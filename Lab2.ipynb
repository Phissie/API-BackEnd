{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Phissie/API-BackEnd/blob/master/Lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrRtJx8KC0mZ"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rpi-techfundamentals/fall2018-materials/blob/master/10-deep-learning/04-pytorch-mnist.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j-Flv1pC0md",
        "outputId": "2ad27352-b0d2-4efe-8567-a6b14c674f18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sQfGKr8CuWR",
        "outputId": "8953f00d-753a-47b2-e87d-44286f06f823"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "batch_size_train = 64\n",
        "batch_size_test = 1000\n",
        "learning_rate = 0.01\n",
        "num_epochs = 30\n",
        "\n",
        "# CIFAR-10 dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "validate_size = int(0.1 * len(dataset))\n",
        "test_size = len(dataset) - train_size - validate_size\n",
        "train_dataset, validate_dataset, test_dataset = random_split(dataset, [train_size, validate_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size_train, shuffle=True)\n",
        "validate_loader = DataLoader(dataset=validate_dataset, batch_size=batch_size_test, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size_test, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "xpWQlzOYCy4F"
      },
      "outputs": [],
      "source": [
        "class CnnNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CnnNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu (x)\n",
        "        x = self.pool(x)\n",
        "        # print(x.shape)\n",
        "\n",
        "        x = x.view(-1, 128 * 4 * 4)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVOLaB877F4P",
        "outputId": "6a1c8756-5a68-4d55-fd9f-8e218bc1d9e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 100: Current Loss = 2.2967\n",
            "Epoch 1, Batch 200: Current Loss = 2.2807\n",
            "Epoch 1, Batch 300: Current Loss = 2.2376\n",
            "Epoch 1, Batch 400: Current Loss = 2.1881\n",
            "Epoch 1, Batch 500: Current Loss = 2.1518\n",
            "Epoch 1, Batch 600: Current Loss = 2.1184\n",
            "Epoch 1 Training Loss: 2.1117\n",
            "Epoch 1 Validation Accuracy: 29.28%\n",
            "Best model saved with accuracy: 29.28%\n",
            "\n",
            "\n",
            "Epoch 2, Batch 100: Current Loss = 1.9009\n",
            "Epoch 2, Batch 200: Current Loss = 1.8626\n",
            "Epoch 2, Batch 300: Current Loss = 1.8318\n",
            "Epoch 2, Batch 400: Current Loss = 1.8061\n",
            "Epoch 2, Batch 500: Current Loss = 1.7790\n",
            "Epoch 2, Batch 600: Current Loss = 1.7496\n",
            "Epoch 2 Training Loss: 1.7453\n",
            "Epoch 2 Validation Accuracy: 41.00%\n",
            "Best model saved with accuracy: 41.00%\n",
            "\n",
            "\n",
            "Epoch 3, Batch 100: Current Loss = 1.5875\n",
            "Epoch 3, Batch 200: Current Loss = 1.5601\n",
            "Epoch 3, Batch 300: Current Loss = 1.5439\n",
            "Epoch 3, Batch 400: Current Loss = 1.5330\n",
            "Epoch 3, Batch 500: Current Loss = 1.5185\n",
            "Epoch 3, Batch 600: Current Loss = 1.5043\n",
            "Epoch 3 Training Loss: 1.5013\n",
            "Epoch 3 Validation Accuracy: 46.86%\n",
            "Best model saved with accuracy: 46.86%\n",
            "\n",
            "\n",
            "Epoch 4, Batch 100: Current Loss = 1.4008\n",
            "Epoch 4, Batch 200: Current Loss = 1.3961\n",
            "Epoch 4, Batch 300: Current Loss = 1.3888\n",
            "Epoch 4, Batch 400: Current Loss = 1.3811\n",
            "Epoch 4, Batch 500: Current Loss = 1.3711\n",
            "Epoch 4, Batch 600: Current Loss = 1.3671\n",
            "Epoch 4 Training Loss: 1.3664\n",
            "Epoch 4 Validation Accuracy: 51.74%\n",
            "Best model saved with accuracy: 51.74%\n",
            "\n",
            "\n",
            "Epoch 5, Batch 100: Current Loss = 1.2782\n",
            "Epoch 5, Batch 200: Current Loss = 1.2819\n",
            "Epoch 5, Batch 300: Current Loss = 1.2726\n",
            "Epoch 5, Batch 400: Current Loss = 1.2704\n",
            "Epoch 5, Batch 500: Current Loss = 1.2657\n",
            "Epoch 5, Batch 600: Current Loss = 1.2583\n",
            "Epoch 5 Training Loss: 1.2578\n",
            "Epoch 5 Validation Accuracy: 55.92%\n",
            "Best model saved with accuracy: 55.92%\n",
            "\n",
            "\n",
            "Epoch 6, Batch 100: Current Loss = 1.1930\n",
            "Epoch 6, Batch 200: Current Loss = 1.1882\n",
            "Epoch 6, Batch 300: Current Loss = 1.1842\n",
            "Epoch 6, Batch 400: Current Loss = 1.1756\n",
            "Epoch 6, Batch 500: Current Loss = 1.1707\n",
            "Epoch 6, Batch 600: Current Loss = 1.1654\n",
            "Epoch 6 Training Loss: 1.1648\n",
            "Epoch 6 Validation Accuracy: 57.20%\n",
            "Best model saved with accuracy: 57.20%\n",
            "\n",
            "\n",
            "Epoch 7, Batch 100: Current Loss = 1.0908\n",
            "Epoch 7, Batch 200: Current Loss = 1.0900\n",
            "Epoch 7, Batch 300: Current Loss = 1.0942\n",
            "Epoch 7, Batch 400: Current Loss = 1.0886\n",
            "Epoch 7, Batch 500: Current Loss = 1.0819\n",
            "Epoch 7, Batch 600: Current Loss = 1.0808\n",
            "Epoch 7 Training Loss: 1.0803\n",
            "Epoch 7 Validation Accuracy: 60.84%\n",
            "Best model saved with accuracy: 60.84%\n",
            "\n",
            "\n",
            "Epoch 8, Batch 100: Current Loss = 1.0248\n",
            "Epoch 8, Batch 200: Current Loss = 1.0334\n",
            "Epoch 8, Batch 300: Current Loss = 1.0195\n",
            "Epoch 8, Batch 400: Current Loss = 1.0168\n",
            "Epoch 8, Batch 500: Current Loss = 1.0083\n",
            "Epoch 8, Batch 600: Current Loss = 1.0072\n",
            "Epoch 8 Training Loss: 1.0068\n",
            "Epoch 8 Validation Accuracy: 61.70%\n",
            "Best model saved with accuracy: 61.70%\n",
            "\n",
            "\n",
            "Epoch 9, Batch 100: Current Loss = 0.9429\n",
            "Epoch 9, Batch 200: Current Loss = 0.9317\n",
            "Epoch 9, Batch 300: Current Loss = 0.9383\n",
            "Epoch 9, Batch 400: Current Loss = 0.9366\n",
            "Epoch 9, Batch 500: Current Loss = 0.9361\n",
            "Epoch 9, Batch 600: Current Loss = 0.9363\n",
            "Epoch 9 Training Loss: 0.9348\n",
            "Epoch 9 Validation Accuracy: 65.54%\n",
            "Best model saved with accuracy: 65.54%\n",
            "\n",
            "\n",
            "Epoch 10, Batch 100: Current Loss = 0.8909\n",
            "Epoch 10, Batch 200: Current Loss = 0.8880\n",
            "Epoch 10, Batch 300: Current Loss = 0.8814\n",
            "Epoch 10, Batch 400: Current Loss = 0.8779\n",
            "Epoch 10, Batch 500: Current Loss = 0.8772\n",
            "Epoch 10, Batch 600: Current Loss = 0.8721\n",
            "Epoch 10 Training Loss: 0.8711\n",
            "Epoch 10 Validation Accuracy: 66.52%\n",
            "Best model saved with accuracy: 66.52%\n",
            "\n",
            "\n",
            "Epoch 11, Batch 100: Current Loss = 0.8025\n",
            "Epoch 11, Batch 200: Current Loss = 0.8136\n",
            "Epoch 11, Batch 300: Current Loss = 0.8195\n",
            "Epoch 11, Batch 400: Current Loss = 0.8231\n",
            "Epoch 11, Batch 500: Current Loss = 0.8185\n",
            "Epoch 11, Batch 600: Current Loss = 0.8161\n",
            "Epoch 11 Training Loss: 0.8138\n",
            "Epoch 11 Validation Accuracy: 66.22%\n",
            "\n",
            "\n",
            "Epoch 12, Batch 100: Current Loss = 0.7603\n",
            "Epoch 12, Batch 200: Current Loss = 0.7703\n",
            "Epoch 12, Batch 300: Current Loss = 0.7667\n",
            "Epoch 12, Batch 400: Current Loss = 0.7654\n",
            "Epoch 12, Batch 500: Current Loss = 0.7610\n",
            "Epoch 12, Batch 600: Current Loss = 0.7591\n",
            "Epoch 12 Training Loss: 0.7579\n",
            "Epoch 12 Validation Accuracy: 67.80%\n",
            "Best model saved with accuracy: 67.80%\n",
            "\n",
            "\n",
            "Epoch 13, Batch 100: Current Loss = 0.6977\n",
            "Epoch 13, Batch 200: Current Loss = 0.6970\n",
            "Epoch 13, Batch 300: Current Loss = 0.6984\n"
          ]
        }
      ],
      "source": [
        "model = CnnNet()\n",
        "# model = BpNet()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.5)\n",
        "\n",
        "best_model = None\n",
        "best_accuracy = 0\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if (batch_idx + 1) % 100 == 0:\n",
        "            print(f'Epoch {epoch}, Batch {batch_idx + 1}: Current Loss = {total_loss / (batch_idx + 1):.4f}')\n",
        "\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    print(f'Epoch {epoch} Training Loss: {average_loss:.4f}')\n",
        "\n",
        "\n",
        "def validate(epoch):\n",
        "    global best_model, best_accuracy\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in validate_loader:\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            total += target.size(0)\n",
        "\n",
        "    accuracy = 100. * correct / total\n",
        "    print(f'Epoch {epoch} Validation Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_model = model.state_dict()\n",
        "        print(\"Best model saved with accuracy: {:.2f}%\".format(best_accuracy))\n",
        "\n",
        "def test():\n",
        "    model.load_state_dict(best_model)\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train(epoch)\n",
        "    validate(epoch)\n",
        "    print('\\n')\n",
        "\n",
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EdA5IMDpb_m"
      },
      "outputs": [],
      "source": [
        "class BpNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BpNet, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(3 * 32 * 32, 512)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 3 * 32 * 32)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vgyqqw7XUXuV"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        self.residual_block1 = self.make_residual_block(64, 64)\n",
        "        self.residual_block2 = self.make_residual_block(64, 128)\n",
        "        self.residual_block3 = self.make_residual_block(128, 256)\n",
        "\n",
        "        self.fc = nn.Linear(256 * 4 * 4, 10)\n",
        "\n",
        "    def make_residual_block(self, in_channels, out_channels, stride=1):\n",
        "        layers = []\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False))\n",
        "            layers.append(nn.BatchNorm2d(out_channels))\n",
        "        layers.extend([\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        ])\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "\n",
        "        x = self.residual_block1(x)\n",
        "        x = self.residual_block2(x)\n",
        "        x = self.residual_block3(x)\n",
        "\n",
        "        x = F.avg_pool2d(x, 4)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x, dim=1)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}